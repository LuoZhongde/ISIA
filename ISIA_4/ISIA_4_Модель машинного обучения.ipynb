{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPSY1cDc/jSVMtDdlmv9Dvp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3CfucnkDnE2w"},"outputs":[],"source":["import pandas as pd\n","import re\n","import csv\n","from ast import literal_eval\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"HGgZqqXFnk_B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711809386204,"user_tz":-480,"elapsed":15975,"user":{"displayName":"闇鴉Master","userId":"12918812363664229580"}},"outputId":"1d3923c4-559a-4331-eb55-082b3caa795f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# 读取wildberries数据集（Ознакомьтесь с набором данных wildberries）\n","csv_wildberries = \"/content/wildberries冬季外套数据（处理后1.0）.csv\"\n","csv_data_wildberries = pd.read_csv(csv_wildberries, low_memory = False)"],"metadata":{"id":"EAT-0n2lnmRE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **特征提取（wildberries）（Извлечение признаков）**"],"metadata":{"id":"_H1ttNQFnod_"}},{"cell_type":"markdown","source":["Список “title”"],"metadata":{"id":"pr3fa8UEny60"}},{"cell_type":"code","source":["# 由Yandex提供的俄语词形分析器（Морфологический анализатор русского языка, предоставленный Яндексом）\n","from pymystem3 import Mystem\n","from gensim.models import Word2Vec\n","\n","# 创建 Mystem 实例（Создайте экземпляр Mystem）\n","mystem = Mystem()\n","\n","# 俄语分词函数（Функция сегментации русского слова）\n","def preprocess_and_tokenize(text):\n","    tokens = mystem.lemmatize(text)\n","    # 移除换行符和空格（Удалите переносы строк и пробелы）\n","    tokens = [token.strip() for token in tokens if token.strip()]\n","    return tokens\n","\n","\n","# 对列\"title\"进行分词（Сегментация слов в столбце \"title\"）\n","csv_data_wildberries['title_token'] = csv_data_wildberries['title'].apply(preprocess_and_tokenize)\n","\n","# 训练 Word2Vec 模型（Обучите модель Word2Vec）\n","word2vec_model = Word2Vec(sentences=csv_data_wildberries['title_token'], vector_size=100, window=5, min_count=1, sg=1)\n","\n","\n","# 构建每个标题的Word2Vec特征表示（Создайте функциональное представление Word2Vec для каждого заголовка）\n","def calculate_word2vec_mean(title_word2ve):\n","    vectors = [word2vec_model.wv[word] for word in title_word2ve if word in word2vec_model.wv]\n","    if len(vectors) > 0:\n","        return np.mean(vectors, axis=0)\n","    else:\n","        # 若所有词都不在词汇表中，则返回全零向量（Если в словаре отсутствуют все слова, возвращаются все нулевые векторы）\n","        return np.zeros(100)\n","\n","csv_data_wildberries['title_word2vec'] = csv_data_wildberries['title_token'].apply(calculate_word2vec_mean)"],"metadata":{"id":"RUJLu9M0n41y","executionInfo":{"status":"ok","timestamp":1711809648080,"user_tz":-480,"elapsed":9474,"user":{"displayName":"闇鴉Master","userId":"12918812363664229580"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"eae71c04-d9ab-498c-d8d8-db5065c2c3ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"]}]},{"cell_type":"markdown","source":["Список “material”"],"metadata":{"id":"pizXhj-An-Fw"}},{"cell_type":"code","source":["\n","# 对列\"material\"进行分词（Сегментация слов в столбце \"material\"）\n","csv_data_wildberries['material_token'] = csv_data_wildberries['material'].apply(preprocess_and_tokenize)\n","\n","# 训练 Word2Vec 模型（Обучите модель Word2Vec）\n","word2vec_model_material = Word2Vec(sentences=csv_data_wildberries['material_token'], vector_size=100, window=5, min_count=1, sg=1)\n","\n","\n","# 构建每个标题的Word2Vec特征表示（Создайте функциональное представление Word2Vec для каждого заголовка）\n","def calculate_word2vec_mean_material(material_word2ve):\n","    vectors = [word2vec_model_material.wv[word] for word in material_word2ve if word in word2vec_model_material.wv]\n","    if len(vectors) > 0:\n","        return np.mean(vectors, axis=0)\n","    else:\n","        # 若所有词都不在词汇表中，则返回全零向量（Если в словаре отсутствуют все слова, возвращаются все нулевые векторы）\n","        return np.zeros(100)\n","\n","csv_data_wildberries['material_word2vec'] = csv_data_wildberries['material_token'].apply(calculate_word2vec_mean_material)"],"metadata":{"id":"pIUtNNEPoBZK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Список “name”"],"metadata":{"id":"I-pBefJ9M22U"}},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","# 构建独热编码函数（Создайте независимую функцию термокодирования）\n","def one_hot_encode_name(data):\n","    # 对列“name”进行独热编码（Независимое термокодирование столбца \"name”）\n","    onehot_encoded_name= pd.get_dummies(csv_data_wildberries['name'])\n","\n","    # 获取列名列表（Получить список имен столбцов）\n","    categories = list(onehot_encoded_name.columns)\n","\n","    # 将独热编码结果保存到字典中（Сохраните результат независимого термокодирования в словаре）\n","    encoding_result_name = {category: i for i, category in enumerate(categories)}\n","\n","    return encoding_result_name, onehot_encoded_name\n","\n","# 对列“name”进行独热编码，并保存编码结果（Индивидуально закодируйте столбец \"name” и сохраните результат кодирования）\n","encoding_result_name, onehot_encoded_name = one_hot_encode_name(csv_data_wildberries)"],"metadata":{"id":"D6w_JBDPM4xy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Список “gender”"],"metadata":{"id":"ahk58vD0MXxZ"}},{"cell_type":"code","source":["# 构建独热编码函数（Создайте независимую функцию термокодирования）\n","def one_hot_encode_gender(data):\n","    # 对列“gender”进行独热编码（Независимое термокодирование столбца \"gender”）\n","    onehot_encoded_gender= pd.get_dummies(csv_data_wildberries['gender'])\n","\n","    # 获取列名列表（Получить список имен столбцов）\n","    categories = list(onehot_encoded_gender.columns)\n","\n","    # 将独热编码结果保存到字典中（Сохраните результат независимого термокодирования в словаре）\n","    encoding_result_gender = {category: i for i, category in enumerate(categories)}\n","\n","    return encoding_result_gender, onehot_encoded_gender\n","\n","# 对列“gender”进行独热编码，并保存编码结果（Индивидуально закодируйте столбец \"gender” и сохраните результат кодирования）\n","encoding_result_gender, onehot_encoded_gender = one_hot_encode_gender(csv_data_wildberries)\n"],"metadata":{"id":"LtuOrdkjMYRo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Список “size”"],"metadata":{"id":"VLmd6V0KL4rl"}},{"cell_type":"code","source":["# 构建独热编码函数（Создайте независимую функцию термокодирования）\n","def one_hot_encode_size(data):\n","    # 对列“size”进行独热编码（Независимое термокодирование столбца \"size”）\n","    onehot_encoded_size= pd.get_dummies(csv_data_wildberries['size'])\n","\n","    # 获取列名列表（Получить список имен столбцов）\n","    categories = list(onehot_encoded_size.columns)\n","\n","    # 将独热编码结果保存到字典中（Сохраните результат независимого термокодирования в словаре）\n","    encoding_result_size = {category: i for i, category in enumerate(categories)}\n","\n","    return encoding_result_size, onehot_encoded_size\n","\n","# 对列“size”进行独热编码，并保存编码结果（Индивидуально закодируйте столбец \"size” и сохраните результат кодирования）\n","encoding_result_size, onehot_encoded_size = one_hot_encode_size(csv_data_wildberries)"],"metadata":{"id":"3uReAfrVMIME"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Список “origin”"],"metadata":{"id":"7IxbFoKKGzLV"}},{"cell_type":"code","source":["# 构建独热编码函数（Создайте независимую функцию термокодирования）\n","def one_hot_encode_origin(data):\n","    # 对列“origin”进行独热编码（Независимое термокодирование столбца \"origin”）\n","    onehot_encoded_origin= pd.get_dummies(csv_data_wildberries['origin'])\n","\n","    # 获取列名列表（Получить список имен столбцов）\n","    categories = list(onehot_encoded_origin.columns)\n","\n","    # 将独热编码结果保存到字典中（Сохраните результат независимого термокодирования в словаре）\n","    encoding_result_origin= {category: i for i, category in enumerate(categories)}\n","\n","    return encoding_result_origin, onehot_encoded_origin\n","\n","# 对列“origin”进行独热编码，并保存编码结果（Индивидуально закодируйте столбец \"origin” и сохраните результат кодирования）\n","encoding_result_origin, onehot_encoded_origin = one_hot_encode_origin(csv_data_wildberries)"],"metadata":{"id":"4Qscc2ENG04g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Список “brand”，“color”"],"metadata":{"id":"HC4X0fiwod7s"}},{"cell_type":"code","source":["# 定义一个函数，用于将文本转换为单词列表，并处理空值（Определите функцию, которая преобразует текст в список слов и обрабатывает нулевые значения）\n","def text_to_wordlist(text):\n","    # 检查是否为空值，如果为空值，返回特殊标记（Проверьте, является ли это нулевым значением, и если это нулевое значение, то будет возвращена специальная отметка）\n","    if pd.isna(text):\n","        return [\"<MISSING>\"]\n","    # 如果不为空值，则正常分词（Если это не нулевое значение, то выполняется обычная сегментация слов）\n","    else:\n","        return text.split()\n","\n","# 列名列表（Список имен столбцов）\n","columns_to_embed = [\"brand\", \"color\"]\n","\n","# 对每一列进行嵌入编码（Вставьте и закодируйте каждый столбец）\n","embeddings = {}\n","for column in columns_to_embed:\n","    sentences = [text_to_wordlist(text) for text in csv_data_wildberries[column]]\n","    model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, sg=1)\n","    embeddings[column] = model\n","\n","# 构建每个列的Word2Vec特征表示（构建每个列的Word2Vec特征表示）\n","def calculate_mean_embedding(words, model):\n","    vectors = [model.wv[word] for word in words if word in model.wv]\n","    if vectors:\n","        return np.mean(vectors, axis=0)\n","    else:\n","        return np.zeros(model.vector_size)\n","\n","# 将每一列转换为Word2Vec特征表示（Преобразуйте каждый столбец в представление объектов Word2Vec）\n","for column in columns_to_embed:\n","    csv_data_wildberries[column + '_word2vec'] = csv_data_wildberries[column].apply(lambda x: calculate_mean_embedding(text_to_wordlist(x), embeddings[column]))"],"metadata":{"id":"xlrPmJkuoiEZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Список “price”"],"metadata":{"id":"49emjhQ2okI1"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","\n","# 创建 MinMaxScaler 对象（Создайте объект MinMaxScaler）\n","scaler_price = MinMaxScaler()\n","# 对列 \"price\" 进行归一化（Нормализовать столбец \"price\"）\n","normalized_price = scaler_price.fit_transform(csv_data_wildberries[['price']])"],"metadata":{"id":"6RKUbLjGonJl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Список “sales_index”"],"metadata":{"id":"H6LQhhlEoonh"}},{"cell_type":"code","source":["# 定义labels到\"1-9\"的映射字典（Определите для сопоставляемого словаря меток значение \"1-9\".）\n","label_sales_index = {'0-100': '1', '100-200': '2', '200-500': '3', '500-1000': '4', '1000-2000': '5', '2000-3000': '6', '3000-4000': '7', '4000-5000': '8', '5000+': '9'}\n","\n","# 使用map函数将labels映射为\"1-9\"（Используйте функцию отображения, чтобы сопоставить метки с \"1-9\".）\n","csv_data_wildberries['sales_index'] = csv_data_wildberries['sales_index'].map(label_sales_index)"],"metadata":{"id":"JKqdtvY-otZq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["转换二维数组（Преобразование 2D-массива）"],"metadata":{"id":"hQ84hy2PozG-"}},{"cell_type":"code","source":["# 提取列“title\"词向量并转换为二维数组形式（Извлеките вектор слов из столбца \"title\" и преобразуйте его в двумерный массив）\n","title_word2vec_vectors = np.array([vec for vec in csv_data_wildberries['title_word2vec']])\n","# 将数组堆叠为二维数组(Объединяйте массивы в двумерные массивы)\n","title_word2vec_vectors = np.vstack(title_word2vec_vectors)\n","\n","# 提取列“brand\"词向量并转换为二维数组形式（Извлеките вектор слов из столбца \"brand\" и преобразуйте его в двумерный массив）\n","brand_word2vec_vectors = np.array([vec for vec in csv_data_wildberries['brand_word2vec']])\n","# 将数组堆叠为二维数组(Объединяйте массивы в двумерные массивы)\n","brand_word2vec_vectors = np.vstack(brand_word2vec_vectors)\n","\n","# 提取列“color\"词向量并转换为二维数组形式（Извлеките вектор слов из столбца \"color\" и преобразуйте его в двумерный массив）\n","color_word2vec_vectors = np.array([vec for vec in csv_data_wildberries['color_word2vec']])\n","# 将数组堆叠为二维数组(Объединяйте массивы в двумерные массивы)\n","color_word2vec_vectors = np.vstack(color_word2vec_vectors)\n","\n","# 提取列“material\"词向量并转换为二维数组形式（Извлеките вектор слов из столбца \"material\" и преобразуйте его в двумерный массив）\n","material_word2vec_vectors = np.array([vec for vec in csv_data_wildberries['material_word2vec']])\n","# 将数组堆叠为二维数组(Объединяйте массивы в двумерные массивы)\n","material_word2vec_vectors = np.vstack(material_word2vec_vectors)\n","\n","# 将列“price\"转换为二维数组(Преобразуйте столбец “price\" в двумерный массив)\n","price_2d = normalized_price.reshape(-1, 1)"],"metadata":{"id":"9c07XecNo3Y6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["分割特征，目标变量，训练集和测试集（Функции сегментации, целевые переменные, обучающий набор и тестовый набор）"],"metadata":{"id":"m4RgNgyLpI3r"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# 合并处理后的特征列到 X 中(Объедините обработанные столбцы объектов в X)\n","X = np.concatenate((title_word2vec_vectors, onehot_encoded_name, brand_word2vec_vectors, onehot_encoded_gender, onehot_encoded_size,\n","            color_word2vec_vectors, material_word2vec_vectors, onehot_encoded_origin, price_2d), axis=1)\n","\n","# 目标列(Целевой столбец)\n","y = csv_data_wildberries['sales_index']\n","one_hot_encoded_columns = pd.get_dummies(y)\n","\n","# 分割训练集和测试集(Разделите обучающий набор и тестовый набор)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"W8WSEVBMpM1B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 训练机器学习模型（Обучение модели машинного **обучения）**"],"metadata":{"id":"bM-0qbeMqdK_"}},{"cell_type":"markdown","source":["随机森林回归（случайная лесная регрессия）"],"metadata":{"id":"ge8VWrX6pTU4"}},{"cell_type":"code","source":["# 训练随机森林回归模型(Обучающая регрессионная модель случайного леса)\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# 创建随机森林回归模型(Создайте регрессионную модель случайного леса)\n","model = RandomForestRegressor()\n","# 树的数量，默认“100\"(Количество деревьев по умолчанию равно “100\".)\n","model = RandomForestRegressor(n_estimators=100)\n","# 树的最大深度，默认为“None\"(Максимальная глубина дерева, значение по умолчанию - \"None\".)\n","model = RandomForestRegressor(max_depth=10)\n","# 分裂的最小样本数，叶子节点的最小样本数，默认为“2\"，“1\"(Минимальное количество разделенных выборок, минимальное количество выборок конечных узлов, значение по умолчанию - “2\", “1\")\n","model = RandomForestRegressor(min_samples_split=2, min_samples_leaf=1)\n","# 每个节点考虑的最大特征数，默认为“auto\"(Максимальное количество объектов, рассматриваемых каждым узлом, по умолчанию равно \"автоматически\".)\n","model = RandomForestRegressor(max_features='auto')\n","# 训练模型(Модель обучения)\n","model.fit(X_train, y_train)\n","\n","\n","\n","# 使用均方差评估模型(Используйте модель оценки среднеквадратичной разницы)\n","from sklearn.metrics import mean_squared_error\n","\n","# 在测试集上评估模型(Оцените модель на тестовом наборе)\n","predictions = model.predict(X_test)\n","mse = mean_squared_error(y_test, predictions)\n","print(\"Mean Squared Error:\", mse)\n","\n","\n","# 使用交叉验证评估模型(Оцените модель с помощью перекрестной проверки)\n","from sklearn.model_selection import cross_val_score\n","\n","# 评估模型(Модель оценки)\n","scores = cross_val_score(model, X_test, y_test, cv=5, scoring='neg_mean_squared_error')\n","mean_mse = -scores.mean()\n","print(\"Cross-validation:\", mean_mse)\n","\n","\n","# 创建一个DataFrame来存储预测值和测试集的真实值(Создайте фрейм данных для хранения прогнозируемого значения и истинного значения тестового набора)\n","results = pd.DataFrame({'预测值(Предполагаемая стоимость)': predictions,\n","              '真实值(реальная стоимость)': y_test})\n","\n","# 显示数据(Отображать данные)\n","print(results)"],"metadata":{"id":"tcEvot46qcOL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711811241600,"user_tz":-480,"elapsed":84711,"user":{"displayName":"闇鴉Master","userId":"12918812363664229580"}},"outputId":"aa04bb8c-dd28-4ed9-a183-511a8cc859ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 1.9863736301991795\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["Cross-validation: 3.289250229777985\n","      预测值(Предполагаемая стоимость) 真实值(реальная стоимость)\n","415                            4.00                       4\n","2233                           2.36                       1\n","1149                           8.90                       9\n","1113                           1.25                       1\n","1225                           6.27                       7\n","...                             ...                     ...\n","1889                           5.52                       9\n","252                            3.61                       4\n","1780                           3.96                       1\n","1406                           8.69                       9\n","940                            3.72                       4\n","\n","[569 rows x 2 columns]\n"]}]},{"cell_type":"markdown","source":["岭回归模型（Модель регрессии гребня）"],"metadata":{"id":"YrM4zbXhthVw"}},{"cell_type":"code","source":["# 训练岭回归模型(Обучающая регрессионная модель гребня)\n","from sklearn.linear_model import Ridge\n","\n","# 创建岭回归模型(Создайте регрессионную модель гребня)\n","model = Ridge()\n","# 正则化强度，值越大，正则化效果越强，默认为1.0(Интенсивность регуляризации, чем больше значение, тем сильнее эффект регуляризации, значение по умолчанию равно 1.0)\n","model = Ridge(alpha=10.0)\n","# 是否拟合截距，默认为True（Независимо от того, подходит ли перехват, значение по умолчанию равно true）\n","model = Ridge(fit_intercept=True)\n","# 求解方法，'auto'表示根据数据自动选择，默认为“auto\"（Метод решения, \"автоматический“ означает, что он выбирается автоматически на основе данных, по умолчанию используется \"автоматический\".）\n","model = Ridge(solver='auto')\n","# 随机种子，默认为None（Случайное начальное значение, по умолчанию - none）\n","model = Ridge(random_state=None)\n","\n","\n","# 训练模型(Модель обучения)\n","model.fit(X_train, y_train)\n","\n","\n","# 使用均方差评估模型(Используйте модель оценки среднеквадратичной разницы)\n","from sklearn.metrics import mean_squared_error\n","\n","# 在测试集上评估模型(Оцените модель на тестовом наборе)\n","predictions = model.predict(X_test)\n","mse = mean_squared_error(y_test, predictions)\n","print(\"Mean Squared Error:\", mse)\n","\n","\n","# 使用交叉验证评估模型(Оцените модель с помощью перекрестной проверки)\n","from sklearn.model_selection import cross_val_score\n","\n","# 评估模型(Модель оценки)\n","scores = cross_val_score(model, X_test, y_test, cv=5, scoring='neg_mean_squared_error')\n","mean_mse = -scores.mean()\n","print(\"Cross-validation:\", mean_mse)\n","\n","\n","# 创建一个DataFrame来存储预测值和测试集的真实值(Создайте фрейм данных для хранения прогнозируемого значения и истинного значения тестового набора)\n","results = pd.DataFrame({'预测值(Предполагаемая стоимость)': predictions,\n","              '真实值(реальная стоимость)': y_test})\n","\n","# 显示数据(Отображать данные)\n","print(results)"],"metadata":{"id":"yZABptTUtmbD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711811241936,"user_tz":-480,"elapsed":347,"user":{"displayName":"闇鴉Master","userId":"12918812363664229580"}},"outputId":"160aaaa2-192f-4a86-f540-bf3109a5a5ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 4.247879157173019\n","Cross-validation: 4.74471144816287\n","      预测值(Предполагаемая стоимость) 真实值(реальная стоимость)\n","415                        3.181908                       4\n","2233                       4.077304                       1\n","1149                       4.837472                       9\n","1113                       2.821053                       1\n","1225                       4.500160                       7\n","...                             ...                     ...\n","1889                       4.708028                       9\n","252                        2.725327                       4\n","1780                       4.085741                       1\n","1406                       4.295148                       9\n","940                        1.696925                       4\n","\n","[569 rows x 2 columns]\n"]}]},{"cell_type":"markdown","source":["梯度提升树"],"metadata":{"id":"grMZb0hntpWx"}},{"cell_type":"code","source":["# 训练梯度提升树模型（Обучающая модель дерева подъема градиента）\n","from sklearn.ensemble import GradientBoostingRegressor\n","\n","# 创建梯度提升树模型（Создайте модель дерева подъема градиента）\n","model = GradientBoostingRegressor()\n","# 损失函数，'ls'表示最小二乘损失函数（默认值）（Функция потерь, \"ls\" означает функцию потерь наименьших квадратов (значение по умолчанию)）\n","model = GradientBoostingRegressor(loss='ls')\n","# 学习率，控制每棵树的贡献，默认值为0.1（Скорость обучения, которая определяет вклад каждого дерева, по умолчанию равна 0,1）\n","model = GradientBoostingRegressor(learning_rate=0.1)\n","# 树的数量，默认值为100（Количество деревьев, значение по умолчанию - 100）\n","model = GradientBoostingRegressor(n_estimators=100)\n","# 每棵树的最大深度，默认值为3（Максимальная глубина каждого дерева, значение по умолчанию - 3）\n","model = GradientBoostingRegressor(max_depth=3)\n","# 拆分内部节点所需的最小样本数，默认值为2（Минимальное количество выборок, необходимое для разделения внутреннего узла, по умолчанию равно 2）\n","model = GradientBoostingRegressor(min_samples_split=2)\n","# 叶节点所需的最小样本数，默认值为1（Минимальное количество выборок, необходимое для конечных узлов, значение по умолчанию равно 1）\n","model = GradientBoostingRegressor(min_samples_leaf=1)\n","# 每棵树考虑的最大特征数，默认值为None（考虑所有特征）(Максимальное количество объектов, рассматриваемых каждым деревом, значение по умолчанию - Нет (рассматриваются все объекты).)\n","model = GradientBoostingRegressor(max_features=None)\n","# 随机种子，默认值为None(Случайное начальное значение, значение по умолчанию - none)\n","model = GradientBoostingRegressor(random_state=None)\n","\n","\n","# 训练模型(Модель обучения)\n","model.fit(X_train, y_train)\n","\n","\n","# 使用均方差评估模型(Используйте модель оценки среднеквадратичной разницы)\n","from sklearn.metrics import mean_squared_error\n","\n","# 在测试集上评估模型(Оцените модель на тестовом наборе)\n","predictions = model.predict(X_test)\n","mse = mean_squared_error(y_test, predictions)\n","print(\"Mean Squared Error:\", mse)\n","\n","\n","# 使用交叉验证评估模型(Оцените модель с помощью перекрестной проверки)\n","from sklearn.model_selection import cross_val_score\n","\n","# 评估模型(Модель оценки)\n","scores = cross_val_score(model, X_test, y_test, cv=5, scoring='neg_mean_squared_error')\n","mean_mse = -scores.mean()\n","print(\"Cross-validation:\", mean_mse)\n","\n","\n","# 创建一个DataFrame来存储预测值和测试集的真实值(Создайте фрейм данных для хранения прогнозируемого значения и истинного значения тестового набора)\n","results = pd.DataFrame({'预测值(Предполагаемая стоимость)': predictions,\n","              '真实值(реальная стоимость)': y_test})\n","\n","# 显示数据(Отображать данные)\n","print(results)"],"metadata":{"id":"fO8qfLTYttC-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711811282752,"user_tz":-480,"elapsed":40819,"user":{"displayName":"闇鴉Master","userId":"12918812363664229580"}},"outputId":"db833e57-61a2-46c5-aa3b-d101e885992a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 2.315773183946338\n","Cross-validation: 3.023500067463224\n","      预测值(Предполагаемая стоимость) 真实值(реальная стоимость)\n","415                        3.387059                       4\n","2233                       2.510435                       1\n","1149                       7.513251                       9\n","1113                       1.858160                       1\n","1225                       4.382992                       7\n","...                             ...                     ...\n","1889                       5.229501                       9\n","252                        3.345102                       4\n","1780                       3.227491                       1\n","1406                       6.511751                       9\n","940                        2.983956                       4\n","\n","[569 rows x 2 columns]\n"]}]}]}